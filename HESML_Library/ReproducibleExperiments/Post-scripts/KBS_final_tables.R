# Description:
#
# This R script processes the raw output files generated
# by the reproducible experiments introduced in [2], with
# the aim of reproducing the results reported in [1].
#
# References:
# ----------
# [1] Lastra-Díaz, J. J., and García-Serrano, A. (2015).
# A new family of information content models with an
# experimental survey on WordNet.
# Knowledge-Based Systems, 89, 509–526.
#
# [2] Lastra-Díaz, J. J., and García-Serrano, A. (2016).
# HESML: a scalable ontology-based semantic similarity
# measures library with a set of reproducible experiments and
# a replication dataset. Submitted for publication to the
# Information Systems Journal.

# We clear all session variables

rm(list = ls())

# IMPORTANT: configuration of the input/output directories
# We define below the input directory for the input raw
# results in CSV file format, and the output directory for the
# final assembled tables in CSV file format.
# You must change these values in order to
# point to the proper directories in your hard drive.
# We also define below the name of the input raw CSV files
# containing the experimental results.

# The input and output directories below must end with '/' in
# Unix-like format to be compatible with Windows
# or Linux-based R distributions.

inputDir = "C:/Versiones_Oficiales_HESML/Full_Trunk_HESML/HESML/HESML_Library/ReproducibleExperiments/RawOutputFiles/"

outputDir = inputDir

# Input raw CSV files generated by the reproducible
# experiments detailed in the paper [1].

KBS_table6_file = "KBS_table6_Taieb.csv"
KBS_table7_file = "KBS_table7_RG65.csv"
KBS_table8_file = "KBS_table8_MC28.csv"
KBS_table9_file = "KBS_table9_Agirre201.csv"
KBS_table10_file = "KBS_table10_PS.csv"
KBS_table11_file = "KBS_table11_simLex665.csv"

# We load the input raw results file

data_KBS_table6<-read.csv(paste(inputDir, sep = "", KBS_table6_file),dec = ".", sep = ';', skip = 1)

data_KBS_table7<-read.csv(paste(inputDir, sep = "", KBS_table7_file),dec = ".", sep = ';')

data_KBS_table8<-read.csv(paste(inputDir, sep = "", KBS_table8_file),dec = ".", sep = ';')

data_KBS_table9<-read.csv(paste(inputDir, sep = "", KBS_table9_file),dec = ".", sep = ';')

data_KBS_table10<-read.csv(paste(inputDir, sep = "", KBS_table10_file),dec = ".", sep = ';')

data_KBS_table11<-read.csv(paste(inputDir, sep = "", KBS_table11_file),dec = ".", sep = ';')

# We are going to compute the table 5, which shows the average
# values for each IC model and IC-based similarity measures in
# each dataset

final_data_KBS_table5 = cbind(IC_models = data_KBS_table7[,1], 0.2 * (data_KBS_table7[,2:15] + data_KBS_table8[,2:15] + data_KBS_table9[,2:15] + data_KBS_table10[,2:15] + data_KBS_table11[,2:15]))

# We compute the average of the row in tables 10 and 11 and add it as last column

final_data_KBS_table5 = cbind(final_data_KBS_table5, Avg_Pearson = rowMeans(final_data_KBS_table5[,c(2,4,6,8,10,12,14)]))

# IMPORTANT: you must install the 'BioPhysConnectoR' package
#before to run the next three lines of code
# We sort the table 5 in descending order by using
# the row-based average Pearson correlation values in
# last column.

detach("package:psych", unload=TRUE)
library(BioPhysConnectoR)

final_data_KBS_table5 = mat.sort(final_data_KBS_table5, 16, decreasing = TRUE)

# Next, we are going to assembly the summary table 4, which
# is defined by the best values of each IC model in
# each dataset

assemblyTable4<-function(table7,table8,table9,table10,table11)
{
    # We get the number of rows of the input matrices

    nrows = nrow(table7)

    #We create the output matrix

    output = matrix(nrow = nrows, ncol = 13)

    # We set the column names

    colnames(output) <- c("RG65.Pearson","RG65.Spearman", "MC28.Pearson","MC28.Spearman","Agirre201.Pearson","Agirre201.Spearman", "PSfull.Pearson","PSfull.Spearman", "SimLex665.Pearson","SimLex665.Spearman","Avg.pearson", "Avg.Spearman", "Both")

    # We set the row names

    rownames(output) <- table7[,1]

    # We iterate on the rows

    for (i in 1:nrows)
    {
            # We get the best values in each dataset

            output[i,1] = max(table7[i,c(2,4,6,8,10,12,14)])
            output[i,2] = max(table7[i,c(3,5,7,9,11,13,15)])

            output[i,3] = max(table8[i,c(2,4,6,8,10,12,14)])
            output[i,4] = max(table8[i,c(3,5,7,9,11,13,15)])

            output[i,5] = max(table9[i,c(2,4,6,8,10,12,14)])
            output[i,6] = max(table9[i,c(3,5,7,9,11,13,15)])

            output[i,7] = max(table10[i,c(2,4,6,8,10,12,14)])
            output[i,8] = max(table10[i,c(3,5,7,9,11,13,15)])

            output[i,9] = max(table11[i,c(2,4,6,8,10,12,14)])
            output[i,10] = max(table11[i,c(3,5,7,9,11,13,15)])

            # We compute the average of the Pearson values

            output[i, 11] = mean(output[i,c(1,3,5,7,9)])
            output[i, 12] = mean(output[i,c(2,4,6,8,10)])
            output[i, 13] = mean(output[i, c(11,12)])
    }

    # We return the final assembled table

    return (output)
}

# We are going to assembly the table 6 containing
# the best values for each similarity measure in each dataset

assemblyTable6<-function(table6, table7,table8,table9,table10,table11)
{
    #We create the output matrix

    output = matrix(nrow = 8, ncol = 13)

    # We set the column names

    colnames(output) <- c("RG65.Pearson","RG65.Spearman", "MC28.Pearson","MC28.Spearman","Agirre201.Pearson","Agirre201.Spearman", "PSfull.Pearson","PSfull.Spearman", "SimLex665.Pearson","SimLex665.Spearman","Avg.pearson", "Avg.Spearman", "Both")

    # We set the row names

    rownames(output) <- c("Resnik","Lin","J&C","P&S","FaITH","Meng et al.","cosJ&C","Hadj Taieb et al.")

    # We iterate on the rows

    for (i in 1:7)
    {
        # We get the best values in each dataset

        output[i,1] = max(table7[,2 * (i - 1) + 2])
        output[i,2] = max(table7[,2 * (i - 1) + 3])

        output[i,3] = max(table8[,2 * (i - 1) + 2])
        output[i,4] = max(table8[,2 * (i - 1) + 3])

        output[i,5] = max(table9[,2 * (i - 1) + 2])
        output[i,6] = max(table9[,2 * (i - 1) + 3])

        output[i,7] = max(table10[,2 * (i - 1) + 2])
        output[i,8] = max(table10[,2 * (i - 1) + 3])

        output[i,9] = max(table11[,2 * (i - 1) + 2])
        output[i,10] = max(table11[,2 * (i - 1) + 3])

        # We compute the average of the Pearson values

        output[i, 11] = mean(output[i,c(1,3,5,7,9)])
        output[i, 12] = mean(output[i,c(2,4,6,8,10)])
        output[i, 13] = mean(output[i, c(11,12)])
    }

    # We copy the values of the Taieb et al. similarity measure in raw table 6

    for (i in 1:10)
    {
        output[8, i] = table6[1, i + 2]
    }

    output[8, 11] = mean(output[8,c(1,3,5,7,9)])
    output[8, 12] = mean(output[8,c(2,4,6,8,10)])
    output[8, 13] = mean(output[8, c(11,12)])

    # We return the final assembled table 6

    return (output)
}

# We build the final table 4 and sort the rows by
# the value in last column

final_data_KBS_table4 <- assemblyTable4(data_KBS_table7, data_KBS_table8, data_KBS_table9, data_KBS_table10, data_KBS_table11)

final_data_KBS_table4 = mat.sort(final_data_KBS_table4, 11, decreasing = TRUE)

# We build the final table 6 and sort the rows by
# the value in last column

final_data_KBS_table6 <- assemblyTable6(data_KBS_table6, data_KBS_table7, data_KBS_table8, data_KBS_table9, data_KBS_table10, data_KBS_table11)

final_data_KBS_table6 = mat.sort(final_data_KBS_table6, 11, decreasing = TRUE)

# We round the results to 4 decimals in order to reproduce the tables in the paper [1] exactly

final_data_KBS_table4 = format(final_data_KBS_table4, digits = 4)

final_data_KBS_table5 = format(final_data_KBS_table5, digits = 4)

final_data_KBS_table6 = format(final_data_KBS_table6, digits = 4)

# We save all the final assembled data tables in order to
# match the assembled tables in the paper [1] exactly.
# The columns in the output CSV files are separated by ','

write.csv(final_data_KBS_table4, file = paste(outputDir, sep="","KBS_final_table_4.csv"))

write.csv(final_data_KBS_table5, file = paste(outputDir, sep="","KBS_final_table_5.csv"))

write.csv(final_data_KBS_table6, file = paste(outputDir, sep="","KBS_final_table_6.csv"))

# THIS SECTION PLOTS THE FIGURE 2 AND 3 IN THE PAPER [1]
# The library 'psych' needs to be installed in order to
# plot the interval confidence figures.

library(psych)

# FIGURE 2
# We are going to build the figure 2 with the interval analysis for the
# IC models as regards the Resnik_trb IC model defined as baseline.
# We use the difference mean between the Pearson correlation values
# reported by each IC model for each IC-based similarity measure.
# We discard the Taieb et al. and CondProbUniform IC models from
# the analysis.
# It means to extract the row vectors in table 5 corresponding to
# the Pearson correlation values reported by each IC model
# in each IC-based similarity measures

# We define the difference mean between each IC model and the baseline

difICmodels = final_data_KBS_table5[,c(2,4,6,8,10,12,14)]
rownames(difICmodels) <- final_data_KBS_table5[,1]

# We extract the resnik_trb IC mdoel defined as baseline (row 6 in table 5)

baselineICmodel = difICmodels[6,]

# We remove the baseline IC model and the Taieb and CPUniform IC models

difICmodels = difICmodels[-c(6,18,19),]

# We compute the difference as regards the baseline IC model

for (i in 1 : nrow(difICmodels))
{
    difICmodels[i,] = as.numeric(difICmodels[i,]) - as.numeric(baselineICmodel)
}

# FIGURE 3
# We are going to build the figure 3 with the interval analysis for the
# IC-based similarity measures as regards the Jiang-Conrath measure
# defined as baseline.

# We extract the reported Pearson correlation value in
# each dataset for each IC-based similarity measure in table5.
# It means to extract the column vectors corresponding to
# the Pearson correlation values reported by each IC-based similarity
# measure for each IC model.

# We define the difference mean between each IC-based similarity
# measure and the J&C baseline

difMeasures = final_data_KBS_table5[,c(2,4,8,10,12,14)]
colnames(difMeasures) <- c("Resnik","Lin", "P&S","FaITH","Meng", "cosJ&C")

baselineJCmeasure = final_data_KBS_table5[,6]

#We compute the differnce as regards the baseline measure

for (i in 1 : ncol(difMeasures))
{
    difMeasures[,i] = as.numeric(difMeasures[,i]) - as.numeric(baselineJCmeasure)
}

# PLOTTING FIGURES 2 AND 3
# We save the two figures as PDF files.
# You will only see the last figure within R

# Finally, we draw the figure 2 in the paper [1] exactly.
# We note that half of the IC model labels dissapear in the
# resulting figure. In the original paper we were obligated
# to edit the EPS file by hand in order to insert
# all the labels.

error.bars(t(difICmodels), ylim = c(-0.035,0.02),xlab = "", main = "95% confidence limits based on a t-distribution (error.bars plot in R)", ylab = "Pearson corr. difference w.r.t. the Resnik_trb IC model (baseline)",eyes=FALSE)
abline(h = 0, lty = 2)

dev.copy2pdf(file = paste(outputDir, sep="","KBS_figure2.pdf"))

# Finally, we draw the figure 3 in the paper [1] exactly

error.bars(difMeasures, ylim = c(-0.03,0.08),xlab = "", main = "95% confidence limits based on a t-distribution (error.bars plot in R)", ylab = "Pearson corr. difference w.r.t. the J&C similarity measure (baseline)",eyes=FALSE)
abline(h = 0, lty = 2)

dev.copy2pdf(file = paste(outputDir, sep="","KBS_figure3.pdf"))
