# Description:
#
# This script loads a collection of word similarity benchmarks generated
# by HESML, whcih contain the raw similarity values for each word pair.
# Then, the script computes a consolidated table including the Pearson and
# Spearman correlation metrics together with the harmonic score of the
# former ones.
#
# References:
# ----------

# We clear all session variables

rm(list = ls())

# IMPORTANT: configuration of the input/output directories
# We define below the input directory for the input raw results
# in CSV file format, and the output directory for the
# final assembled tables in CSV file format.
# You must change these values in order to
# point to the proper directories in your hard drive.
# We also define below the name of the input raw CSV files
# containing the experimental results.

# The input and output directories below must end with '/' in
# Unix-like format to be compatible with Windows
# or Linux-based R distributions.

inputDir = "C:/Versiones_Git_Oficiales_HESML/HESML/HESML_Library/ReproducibleExperiments/Embeddings_vs_OntologyMeasures_paper/RawOutputFiles/"
outputDir = "C:/Versiones_Git_Oficiales_HESML/HESML/HESML_Library/ReproducibleExperiments/Embeddings_vs_OntologyMeasures_paper/ProcessedOutputFiles/"


# Input raw CSV files generated by the reproducible experiments detailed
# in the paper.

raw_MC28_file = "raw_similarity_values_MC28_dataset.csv"
raw_RG65_file = "raw_similarity_values_RG65_dataset.csv"
raw_PSfull_file = "raw_similarity_values_PSfull_dataset.csv"
raw_Agirre201_file = "raw_similarity_values_Agirre201_lowercase_dataset.csv"
raw_SimLex665_file = "raw_similarity_values_SimLex665_dataset.csv"
raw_MTurk771_file = "raw_similarity_values_MTurk771_dataset.csv"
raw_MTurk287_235_file = "raw_similarity_values_MTurk287-235_dataset.csv"
raw_WS353Rel_file = "raw_similarity_values_WS353Rel_dataset.csv"
raw_Rel122_file = "raw_similarity_values_Rel122_dataset.csv"
raw_WS353Full_file = "raw_similarity_values_WS353Full_dataset.csv"
raw_SimLex111_file = "raw_similarity_values_SimLex111_dataset.csv"
raw_SimLex222_file = "raw_similarity_values_SimLex222_dataset.csv"
raw_SimLex999_file = "raw_similarity_values_SimLex999_dataset.csv"
raw_SimVerb3500_file = "raw_similarity_values_SimVerb3500_dataset.csv"
raw_MEN_file = "raw_similarity_values_MEN_dataset.csv"
raw_YP130_file = "raw_similarity_values_YP130_dataset.csv"
raw_RareWords2034_file = "raw_similarity_values_RareWords2034_dataset.csv"
raw_RareWords1401_file = "raw_similarity_values_RareWords1401_dataset.csv"
raw_SCWS1994_file = "raw_similarity_values_SCWS1994_dataset.csv"

# We load the input raw results file

rawdata_MC28<-read.csv(paste(inputDir, sep = "", raw_MC28_file),dec = ".", sep = ';')
rawdata_RG65<-read.csv(paste(inputDir, sep = "", raw_RG65_file),dec = ".", sep = ';')
rawdata_PSfull<-read.csv(paste(inputDir, sep = "", raw_PSfull_file),dec = ".", sep = ';')
rawdata_Agirre201<-read.csv(paste(inputDir, sep = "", raw_Agirre201_file),dec = ".", sep = ';')
rawdata_SimLex665<-read.csv(paste(inputDir, sep = "", raw_SimLex665_file),dec = ".", sep = ';')
rawdata_MTurk771<-read.csv(paste(inputDir, sep = "", raw_MTurk771_file),dec = ".", sep = ';')
rawdata_MTurk287_235<-read.csv(paste(inputDir, sep = "", raw_MTurk287_235_file),dec = ".", sep = ';')
rawdata_WS353Rel<-read.csv(paste(inputDir, sep = "", raw_WS353Rel_file),dec = ".", sep = ';')
rawdata_Rel122<-read.csv(paste(inputDir, sep = "", raw_Rel122_file),dec = ".", sep = ';')
rawdata_WS353Full<-read.csv(paste(inputDir, sep = "", raw_WS353Full_file),dec = ".", sep = ';')
rawdata_SimLex111<-read.csv(paste(inputDir, sep = "", raw_SimLex111_file),dec = ".", sep = ';')
rawdata_SimLex222<-read.csv(paste(inputDir, sep = "", raw_SimLex222_file),dec = ".", sep = ';')
rawdata_SimLex999<-read.csv(paste(inputDir, sep = "", raw_SimLex999_file),dec = ".", sep = ';')
rawdata_SimVerb3500<-read.csv(paste(inputDir, sep = "", raw_SimVerb3500_file),dec = ".", sep = ';')
rawdata_MEN<-read.csv(paste(inputDir, sep = "", raw_MEN_file),dec = ".", sep = ';')
rawdata_YP130<-read.csv(paste(inputDir, sep = "", raw_YP130_file),dec = ".", sep = ';')
rawdata_RareWords2034<-read.csv(paste(inputDir, sep = "", raw_RareWords2034_file),dec = ".", sep = ';')
rawdata_RareWords1401<-read.csv(paste(inputDir, sep = "", raw_RareWords1401_file),dec = ".", sep = ';')
rawdata_SCWS1994<-read.csv(paste(inputDir, sep = "", raw_SCWS1994_file),dec = ".", sep = ';')

# IMPORTANT: you must install the 'BioPhysConnectoR' package before to run the next three lines of code
# We sort the tables 3,4 and 5 in descending order by using the column-based Average values (last row)

library(BioPhysConnectoR)

# ---------------------------------------------------------------------
# Table 1: Pearson, Spearman and Harmonic mean metrics of all measures
# and embeddings in the 5 similarity datasets evaluated both by the
# ontoloy-based measures basedon Wordnet as the pre-trained word
# embedding models.
# ---------------------------------------------------------------------

# We define all datasets represented in table 1

rawdataSimNounDatasets = list(rawdata_MC28, rawdata_RG65, rawdata_PSfull, rawdata_Agirre201, rawdata_SimLex665)

# We create a separate table for each metric

table_Pearson_SimDatasets<-matrix(nrow = ncol(rawdata_MC28) - 2, ncol = length(rawdataSimNounDatasets))

colnames(table_Pearson_SimDatasets)<-c("MC28", "RG65", "PSfull", "Agirre201", "SimLex665")
rownames(table_Pearson_SimDatasets)<-colnames(rawdata_MC28)[3:ncol(rawdata_MC28)]

table_Spearman_SimDatasets<-matrix(nrow = ncol(rawdata_MC28) - 2, ncol = length(rawdataSimNounDatasets))

colnames(table_Spearman_SimDatasets)<-colnames(table_Pearson_SimDatasets)
rownames(table_Spearman_SimDatasets)<-colnames(rawdata_MC28)[3:ncol(rawdata_MC28)]

table_Harmonic_SimDatasets<-matrix(nrow = ncol(rawdata_MC28) - 2, ncol = length(rawdataSimNounDatasets))

colnames(table_Harmonic_SimDatasets)<-colnames(table_Pearson_SimDatasets)
rownames(table_Harmonic_SimDatasets)<-colnames(rawdata_MC28)[3:ncol(rawdata_MC28)]

nMeasures = nrow(table_Pearson_SimDatasets)
nDatasets = length(rawdataSimNounDatasets)

for (iDataset in 1:nDatasets)
{
	# We get the raw data of the next dataset

	rawdata = rawdataSimNounDatasets[[iDataset]]

	# We evaluate the Pearson, Spearman and Harmonic metrics for each measure in the current dataset

	for (iMeasure in 1:nMeasures)
	{
		table_Pearson_SimDatasets[iMeasure, iDataset] = cor(rawdata[,2], rawdata[, iMeasure + 2], method = "pearson")
		table_Spearman_SimDatasets[iMeasure, iDataset] = cor(rawdata[,2], rawdata[, iMeasure + 2], method = "spearman")
		table_Harmonic_SimDatasets[iMeasure, iDataset] = 2.0 * table_Pearson_SimDatasets[iMeasure, iDataset] * table_Spearman_SimDatasets[iMeasure, iDataset] / (table_Pearson_SimDatasets[iMeasure, iDataset] + table_Spearman_SimDatasets[iMeasure, iDataset])
	}
}

# We compute the average values per row and sort the rows

table_Pearson_SimDatasets = cbind(table_Pearson_SimDatasets, Avg = rowMeans(table_Pearson_SimDatasets[1:nrow(table_Pearson_SimDatasets),]))
table_Pearson_SimDatasets = mat.sort(table_Pearson_SimDatasets, ncol(table_Pearson_SimDatasets), decreasing = TRUE)

table_Spearman_SimDatasets = cbind(table_Spearman_SimDatasets, Avg = rowMeans(table_Spearman_SimDatasets[1:nrow(table_Spearman_SimDatasets),]))
table_Spearman_SimDatasets = mat.sort(table_Spearman_SimDatasets, ncol(table_Spearman_SimDatasets), decreasing = TRUE)

table_Harmonic_SimDatasets = cbind(table_Harmonic_SimDatasets, Avg = rowMeans(table_Harmonic_SimDatasets[1:nrow(table_Harmonic_SimDatasets),]))
table_Harmonic_SimDatasets = mat.sort(table_Harmonic_SimDatasets, ncol(table_Harmonic_SimDatasets), decreasing = TRUE)

# We make a copy of the tables in order to round their values to 3 decimal digits

table_Pearson_SimDatasets_rounded = round(table_Pearson_SimDatasets, 3);
table_Spearman_SimDatasets_rounded = round(table_Spearman_SimDatasets, 3);
table_Harmonic_SimDatasets_rounded = round(table_Harmonic_SimDatasets, 3);

# We save all final assembled data tables 

write.csv(table_Pearson_SimDatasets, file = paste(outputDir, sep="","table_Pearson_SimDatasets.csv"))
write.csv(table_Pearson_SimDatasets_rounded, file = paste(outputDir, sep="","table_Pearson_SimDatasets_rounded.csv"))

write.csv(table_Spearman_SimDatasets, file = paste(outputDir, sep="","table_Spearman_SimDatasets.csv"))
write.csv(table_Spearman_SimDatasets_rounded, file = paste(outputDir, sep="","table_Spearman_SimDatasets_rounded.csv"))

write.csv(table_Harmonic_SimDatasets, file = paste(outputDir, sep="","table_Harmonic_SimDatasets.csv"))
write.csv(table_Harmonic_SimDatasets_rounded, file = paste(outputDir, sep="","table_Harmonic_SimDatasets_rounded.csv"))

# ---------------------------------------------------------------------
# Table 2: Pearson, Spearman and Harmonic mean metrics of all measures
# and embeddings in the 4 relatedness datasets evaluated both by the
# ontoloy-based measures basedon Wordnet as the pre-trained word
# embedding models.
# ---------------------------------------------------------------------

# We define all datasets represented in table 2

rawdataRelNounDatasets = list(rawdata_MTurk771, rawdata_MTurk287_235, rawdata_WS353Rel, rawdata_Rel122)

# We create the table 2

# We create a separate table for each metric

table_Pearson_RelDatasets<-matrix(nrow = ncol(rawdata_MC28) - 2, ncol = length(rawdataRelmNounDatasets))

colnames(table_Pearson_RelDatasets)<-c("MTurk771", "MTurk287_235", "WS353Rel", "Rel122")
rownames(table_Pearson_RelDatasets)<-colnames(rawdata_MC28)[3:ncol(rawdata_MC28)]

table_Spearman_RelDatasets<-matrix(nrow = ncol(rawdata_MC28) - 2, ncol = length(rawdataRelNounDatasets))

colnames(table_Spearman_RelDatasets)<-colnames(table_Pearson_RelDatasets)
rownames(table_Spearman_RelDatasets)<-colnames(rawdata_MC28)[3:ncol(rawdata_MC28)]

table_Harmonic_RelDatasets<-matrix(nrow = ncol(rawdata_MC28) - 2, ncol = length(rawdataRelNounDatasets))

colnames(table_Harmonic_RelDatasets)<-colnames(table_Pearson_RelDatasets)
rownames(table_Harmonic_RelDatasets)<-colnames(rawdata_MC28)[3:ncol(rawdata_MC28)]

nMeasures = nrow(table_Pearson_RelDatasets)
nDatasets = length(rawdataRelNounDatasets)

for (iDataset in 1:nDatasets)
{
	# We get the raw data of the next dataset

	rawdata = rawdataRelNounDatasets[[iDataset]]

	# We evaluate the Pearson, Spearman and Harmonic metrics for each measure in the current dataset

	for (iMeasure in 1:nMeasures)
	{
		table_Pearson_RelDatasets[iMeasure, iDataset] = cor(rawdata[,2], rawdata[, iMeasure + 2], method = "pearson")
		table_Spearman_RelDatasets[iMeasure, iDataset] = cor(rawdata[,2], rawdata[, iMeasure + 2], method = "spearman")
		table_Harmonic_RelDatasets[iMeasure, iDataset] = 2.0 * table_Pearson_RelDatasets[iMeasure, iDataset] * table_Spearman_RelDatasets[iMeasure, iDataset] / (table_Pearson_RelDatasets[iMeasure, iDataset] + table_Spearman_RelDatasets[iMeasure, iDataset])
	}
}

# We compute the average values per row and sort the rows

table_Pearson_RelDatasets = cbind(table_Pearson_RelDatasets, Avg = rowMeans(table_Pearson_RelDatasets[1:nrow(table_Pearson_RelDatasets),]))
table_Pearson_RelDatasets = mat.sort(table_Pearson_RelDatasets, ncol(table_Pearson_RelDatasets), decreasing = TRUE)

table_Spearman_RelDatasets = cbind(table_Spearman_RelDatasets, Avg = rowMeans(table_Spearman_RelDatasets[1:nrow(table_Spearman_RelDatasets),]))
table_Spearman_RelDatasets = mat.sort(table_Spearman_RelDatasets, ncol(table_Spearman_RelDatasets), decreasing = TRUE)

table_Harmonic_RelDatasets = cbind(table_Harmonic_RelDatasets, Avg = rowMeans(table_Harmonic_RelDatasets[1:nrow(table_Harmonic_RelDatasets),]))
table_Harmonic_RelDatasets = mat.sort(table_Harmonic_RelDatasets, ncol(table_Harmonic_RelDatasets), decreasing = TRUE)

# We make a copy of the tables in order to round their values to 3 decimal digits

table_Pearson_RelDatasets_rounded = round(table_Pearson_RelDatasets, 3);
table_Spearman_RelDatasets_rounded = round(table_Spearman_RelDatasets, 3);
table_Harmonic_RelDatasets_rounded = round(table_Harmonic_RelDatasets, 3);

# We save all final assembled data tables 

write.csv(table_Pearson_RelDatasets, file = paste(outputDir, sep="","table_Pearson_RelDatasets.csv"))
write.csv(table_Pearson_RelDatasets_rounded, file = paste(outputDir, sep="","table_Pearson_RelDatasets_rounded.csv"))

write.csv(table_Spearman_RelDatasets, file = paste(outputDir, sep="","table_Spearman_RelDatasets.csv"))
write.csv(table_Spearman_RelDatasets_rounded, file = paste(outputDir, sep="","table_Spearman_RelDatasets_rounded.csv"))

write.csv(table_Harmonic_RelDatasets, file = paste(outputDir, sep="","table_Harmonic_RelDatasets.csv"))
write.csv(table_Harmonic_RelDatasets_rounded, file = paste(outputDir, sep="","table_Harmonic_RelDatasets_rounded.csv"))

# ---------------------------------------------------------------------
# Table 3, 4 and 5: Pearson, Spearman and Harmonic metrics of all
# pre-trained embeddings models in all datasets. Rows contain datasets
# whilst columns contain the perfromance of each word embedding model
# in each dataset. Columns are sorted in descending order from
# left to right. Leftmost columns show best performing embedding models.
# ---------------------------------------------------------------------

# We define all datasets

rawdataAllDatasets = list(rawdata_MC28, rawdata_RG65, rawdata_PSfull, rawdata_Agirre201, rawdata_SimLex665, rawdata_MTurk771, rawdata_MTurk287_235, rawdata_WS353Rel, rawdata_Rel122, rawdata_WS353Full, rawdata_SimLex111, rawdata_SimLex222, rawdata_SimLex999, rawdata_SimVerb3500, rawdata_MEN, rawdata_YP130, rawdata_RareWords2034, rawdata_RareWords1401, rawdata_SCWS1994);

# We create the tables 3,4 and 5

table_Pearson_allEmbeddings<-matrix(ncol = 11, nrow = length(rawdataAllDatasets))
table4<-matrix(ncol = 11, nrow = length(rawdataAllDatasets))
table5<-matrix(ncol = 11, nrow = length(rawdataAllDatasets))

nOntologyBasedMeasures = 21;

rownames(table_Pearson_allEmbeddings)<-c("MC28", "RG65", "PSfull", "Agirre201", "SimLex665", "MTurk771", "MTurk287_235", "WS353Rel", "Rel122", "WS353Full", "SimLex111", "SimLex222", "SimLex999", "SimVerb3500", "MEN", "YP130", "RW2034", "RW1401", "SCWS1994");
colnames(table_Pearson_allEmbeddings)<-colnames(rawdata_MC28)[nOntologyBasedMeasures + 3:ncol(rawdata_MC28)]

rownames(table4)<-rownames(table3)
colnames(table4)<-colnames(table3)

rownames(table5)<-rownames(table3)
colnames(table5)<-colnames(table3)

nMeasures = ncol(table3)
nDatasets = length(rawdataAllDatasets)

for (iDataset in 1:nDatasets)
{
	# We get the raw data of the next dataset

	rawdata = rawdataAllDatasets[[iDataset]]

	# We define the offset position to extract the column of each embedding model.
	# First nine datasets include the evaluation of 21 ontology-based measures and
	# 11 embedding models. However, the remaining 10 datasets are only evaluated
	# on the embedding models.

	if (iDataset < 10)
	{
		iOffset = 23;
	}
	else
	{
		iOffset = 2;
	}

	# We evaluate the Pearson, Spearman and Harmonic metrics for each measure in the current dataset

	for (iMeasure in 1:nMeasures)
	{
		table_Pearson_allEmbeddings[iDataset, iMeasure] = cor(rawdata[,2], rawdata[, iMeasure + iOffset], method = "pearson")
		table4[iDataset, iMeasure] = cor(rawdata[,2], rawdata[, iMeasure + iOffset], method = "spearman")
		table5[iDataset, iMeasure] = 2 * table_Pearson_allEmbeddings[iDataset, iMeasure] * table4[iDataset, iMeasure] / (table_Pearson_allEmbeddings[iDataset, iMeasure] + table4[iDataset, iMeasure])
	}
}

# We transpose the matrix in order to compute the average of columns

table_Pearson_allEmbeddings = rbind(table_Pearson_allEmbeddings, Avg = colMeans(table_Pearson_allEmbeddings[,1:ncol(table_Pearson_allEmbeddings)]))
table_Spearman_allEmbeddings = rbind(table_Spearman_allEmbeddings, Avg = colMeans(table_Spearman_allEmbeddings[,1:ncol(table_Spearman_allEmbeddings)]))
table_Harmonic_allEmbeddings = rbind(table_Harmonic_allEmbeddings, Avg = colMeans(table_Harmonic_allEmbeddings[,1:ncol(table_Harmonic_allEmbeddings)]))

# We transpose the matrices in order to sort them according to the
# average value obtained by each embedding model

table_Pearson_allEmbeddings = t(table_Pearson_allEmbeddings)
table_Pearson_allEmbeddings = mat.sort(table_Pearson_allEmbeddings, ncol(table_Pearson_allEmbeddings), decreasing = TRUE)
table_Pearson_allEmbeddings = t(table_Pearson_allEmbeddings)

table_Spearman_allEmbeddings = t(table_Spearman_allEmbeddings)
table_Spearman_allEmbeddings = mat.sort(table_Spearman_allEmbeddings, ncol(table_Spearman_allEmbeddings), decreasing = TRUE)
table_Spearman_allEmbeddings = t(table_Spearman_allEmbeddings)

table_Harmonic_allEmbeddings = t(table_Harmonic_allEmbeddings)
table_Harmonic_allEmbeddings = mat.sort(table_Harmonic_allEmbeddings, ncol(table_Harmonic_allEmbeddings), decreasing = TRUE)
table_Harmonic_allEmbeddings = t(table_Harmonic_allEmbeddings)

# We make a copy of the tables in order to round their values to 3 decimal digits

table_Pearson_allEmbeddings_rounded = round(table_Pearson_allEmbeddings, 3);
table_Spearman_allEmbeddings_rounded = round(table_Spearman_allEmbeddings, 3);
table_Harmonic_allEmbeddings_rounded = round(table_Harmonic_allEmbeddings, 3);

# We save all the final assembled data tables 

write.csv(table_Pearson_allEmbeddings, file = paste(outputDir, sep="","table_Pearson_allEmbeddings_raw_values.csv"))
write.csv(table_Pearson_allEmbeddings_rounded, file = paste(outputDir, sep="","table_Pearson_allEmbeddings_rounded_values.csv"))

write.csv(table_Spearman_allEmbeddings, file = paste(outputDir, sep="","table_Spearman_allEmbeddings_raw_values.csv"))
write.csv(table_Spearman_allEmbeddings_rounded, file = paste(outputDir, sep="","table_Spearman_allEmbeddings_rounded_values.csv"))

write.csv(table_Harmonic_allEmbeddings, file = paste(outputDir, sep="","table_Harmonic_allEmbeddings_raw_values.csv"))
write.csv(table_Harmonic_allEmbeddings_rounded, file = paste(outputDir, sep="","table_Harmonic_allEmbeddings_rounded_values.csv"))


